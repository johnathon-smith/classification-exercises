{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e3c2f0",
   "metadata": {},
   "source": [
    "### Use the titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245f578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import acquire\n",
    "import prepare\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d82106",
   "metadata": {},
   "source": [
    "### Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b216d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca2cf0",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a704b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>num_sib_and_sp</th>\n",
       "      <th>num_par_and_ch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  num_sib_and_sp  num_par_and_ch     fare  alone  sex_male  \\\n",
       "0         0       3               1               0   7.2500      0         1   \n",
       "1         1       1               1               0  71.2833      0         0   \n",
       "2         1       3               0               0   7.9250      1         0   \n",
       "3         1       1               1               0  53.1000      0         0   \n",
       "4         0       3               0               0   8.0500      1         1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  \n",
       "3                       0                        1  \n",
       "4                       0                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = prepare.prep_titanic(titanic)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6ee30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train, validate, and test subsets\n",
    "train, validate, test = prepare.train_validate_test_split(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7428a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the X and y variables\n",
    "X_train, y_train = train.drop('survived', axis = 1), train.survived\n",
    "X_validate, y_validate = validate.drop('survived', axis = 1), validate.survived\n",
    "X_test, y_test = test.drop('survived', axis = 1), test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8a4f2",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "### What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb6ab4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target variable is survived. Baseline will be the most common value.\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ab1203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616822429906542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since most people did not survive, this will be the baseline prediction.\n",
    "#Use the dummy classifier to set the baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline = DummyClassifier(strategy = 'constant', constant = 0)\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "#Now get the baseline accuracy\n",
    "baseline.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261b9ac",
   "metadata": {},
   "source": [
    "### Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d41a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the decision tree classifier\n",
    "model1 = DecisionTreeClassifier(max_depth = 5, random_state = 123)\n",
    "\n",
    "#Fit the model\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "model1_preds = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c17d5",
   "metadata": {},
   "source": [
    "### Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7531cba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373493975903614"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model score\n",
    "model1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1f8043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  303    4\n",
       "1   77  114"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, model1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3eff250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       307\n",
      "           1       0.97      0.60      0.74       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.88      0.79      0.81       498\n",
      "weighted avg       0.86      0.84      0.83       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_train, model1_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba7662",
   "metadata": {},
   "source": [
    "### Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1ce19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision, recall, f1-score, and support are listed above\n",
    "tp_1 = 114\n",
    "tn_1 = 303\n",
    "fp_1 = 4\n",
    "fn_1 = 77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90d133",
   "metadata": {},
   "source": [
    "### Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35892dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate model\n",
    "model2 = DecisionTreeClassifier(max_depth = 9, random_state = 123)\n",
    "\n",
    "#Fit the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "model2_preds = model2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab61c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096385542168675"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model score\n",
    "model2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98798b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  298    9\n",
       "1   36  155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "#index = actual\n",
    "#columns = predictions\n",
    "pd.DataFrame(confusion_matrix(y_train, model2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc460ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.95      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.92      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.91       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_train, model2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf9f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate tp, tn, fp, fn\n",
    "tp = 155\n",
    "tn = 298\n",
    "fp = 9\n",
    "fn = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf2a66",
   "metadata": {},
   "source": [
    "### Which model performs better on your in-sample data?\n",
    "\n",
    "My model2 performs better on in sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36530c3",
   "metadata": {},
   "source": [
    "### Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0994834d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7570093457943925"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare general accuracies\n",
    "\n",
    "#For model1\n",
    "model1.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "578edcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7616822429906542"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For model2\n",
    "model2.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09092f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       132\n",
      "           1       0.83      0.46      0.59        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.78      0.70      0.71       214\n",
      "weighted avg       0.77      0.76      0.74       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check classification reports\n",
    "\n",
    "#For model1\n",
    "model1_preds = model1.predict(X_validate)\n",
    "print(classification_report(y_validate, model1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "179f6e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       132\n",
      "           1       0.72      0.61      0.66        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.75      0.73      0.74       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For model2\n",
    "model2_preds = model2.predict(X_validate)\n",
    "print(classification_report(y_validate, model2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa84aa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  124   8\n",
       "1   44  38"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check confusion matrices\n",
    "\n",
    "#For model1\n",
    "pd.DataFrame(confusion_matrix(y_validate, model1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee7237e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  113  19\n",
       "1   32  50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For model2\n",
    "pd.DataFrame(confusion_matrix(y_validate, model2_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cc57a",
   "metadata": {},
   "source": [
    "While accuracy is about the same for both models, their precision and recall for survivor predictions were quite different. Based on these numbers, and assuming its more important to predict who survived rather than those who did not, it seems model2 is the better performer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5eca0f",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb57aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Instantiate the model\n",
    "clf_1 = RandomForestClassifier(min_samples_leaf = 1, max_depth = 10, random_state = 123)\n",
    "\n",
    "#Fit the model to training data\n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitons\n",
    "clf_1_preds = clf_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3a704",
   "metadata": {},
   "source": [
    "### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e194e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model score\n",
    "accuracy = clf_1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25214ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  301    6\n",
       "1   22  169"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, clf_1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e54c3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       307\n",
      "           1       0.97      0.88      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.95      0.93      0.94       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(classification_report(y_train, clf_1_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5348d9d",
   "metadata": {},
   "source": [
    "### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb3f0419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9437751004016064\n",
      "True Positives: 169\n",
      "False Positives: 6\n",
      "True Negatives: 301\n",
      "False Negatives: 22\n"
     ]
    }
   ],
   "source": [
    "#Precision, recall, f1-score and support are all clearly labeled above.\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'True Positives: 169')\n",
    "print(f'False Positives: 6')\n",
    "print(f'True Negatives: 301')\n",
    "print(f'False Negatives: 22')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f0240",
   "metadata": {},
   "source": [
    "### Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbe56b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "clf_2 = RandomForestClassifier(random_state = 123, min_samples_leaf = 3, max_depth = 7)\n",
    "\n",
    "#Fit the model\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "#Make preds\n",
    "clf_2_preds = clf_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95afda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = clf_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a131092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  294   13\n",
       "1   48  143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, clf_2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbee1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.87       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_train, clf_2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d3c4005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8775100401606426\n",
      "True Positives: 143\n",
      "False Positives: 13\n",
      "True Negatives: 294\n",
      "False Negatives: 48\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print('True Positives: 143')\n",
    "print('False Positives: 13')\n",
    "print('True Negatives: 294')\n",
    "print('False Negatives: 48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fa9671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "clf_3 = RandomForestClassifier(random_state = 123, min_samples_leaf = 5, max_depth = 4)\n",
    "\n",
    "#Fit the model\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "#Make preds\n",
    "clf_3_preds = clf_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c323463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = clf_3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0726341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  287   20\n",
       "1   66  125"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, clf_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab05bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_train, clf_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25ce0616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8273092369477911\n",
      "True Positives: 125\n",
      "False Positives: 20\n",
      "True Negatives: 287\n",
      "False Negatives: 66\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print('True Positives: 125')\n",
    "print('False Positives: 20')\n",
    "print('True Negatives: 287')\n",
    "print('False Negatives: 66')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85131015",
   "metadata": {},
   "source": [
    "### What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed3a54",
   "metadata": {},
   "source": [
    "With every increase in min_samples_leaf and decrease in max_depth, the models perform worse. True positives and negatives go down, and false positives and negatives go up. My first model with min_samples_leaf = 1 and max_depth = 10 performed the best on the training data. I think this is because the higher max_depth is allowing the model to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb860907",
   "metadata": {},
   "source": [
    "### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c98a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, random_state=123)\n",
      "Accuracy: 0.9437751004016064\n",
      "True Positives: 169\n",
      "False Positives: 6\n",
      "True Negatives: 301\n",
      "False Negatvies: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       307\n",
      "           1       0.97      0.88      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.95      0.93      0.94       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=7, min_samples_leaf=3, random_state=123)\n",
      "Accuracy: 0.8775100401606426\n",
      "True Positives: 143\n",
      "False Positives: 13\n",
      "True Negatives: 294\n",
      "False Negatvies: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.87       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=4, min_samples_leaf=5, random_state=123)\n",
      "Accuracy: 0.8273092369477911\n",
      "True Positives: 125\n",
      "False Positives: 20\n",
      "True Negatives: 287\n",
      "False Negatvies: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing each model on Train data set\n",
    "models = [clf_1, clf_2, clf_3]\n",
    "\n",
    "for model in models:\n",
    "    preds = model.predict(X_train)\n",
    "    print(f'{model}')\n",
    "    print(f'Accuracy: {model.score(X_train, y_train)}')\n",
    "    print(f'True Positives: {confusion_matrix(y_train, preds)[1][1]}')\n",
    "    print(f'False Positives: {confusion_matrix(y_train, preds)[0][1]}')\n",
    "    print(f'True Negatives: {confusion_matrix(y_train, preds)[0][0]}')\n",
    "    print(f'False Negatvies: {confusion_matrix(y_train, preds)[1][0]}')\n",
    "    print(classification_report(y_train, preds))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b4032e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, random_state=123)\n",
      "Accuracy: 0.7850467289719626\n",
      "True Positives: 51\n",
      "False Positives: 15\n",
      "True Negatives: 117\n",
      "False Negatvies: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       132\n",
      "           1       0.77      0.62      0.69        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.75      0.76       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=7, min_samples_leaf=3, random_state=123)\n",
      "Accuracy: 0.8130841121495327\n",
      "True Positives: 53\n",
      "False Positives: 11\n",
      "True Negatives: 121\n",
      "False Negatvies: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       132\n",
      "           1       0.83      0.65      0.73        82\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.82      0.78      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=4, min_samples_leaf=5, random_state=123)\n",
      "Accuracy: 0.7850467289719626\n",
      "True Positives: 49\n",
      "False Positives: 13\n",
      "True Negatives: 119\n",
      "False Negatvies: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       132\n",
      "           1       0.79      0.60      0.68        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.75      0.76       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing each model on validate data set\n",
    "\n",
    "for model in models:\n",
    "    preds = model.predict(X_validate)\n",
    "    print(f'{model}')\n",
    "    print(f'Accuracy: {model.score(X_validate, y_validate)}')\n",
    "    print(f'True Positives: {confusion_matrix(y_validate, preds)[1][1]}')\n",
    "    print(f'False Positives: {confusion_matrix(y_validate, preds)[0][1]}')\n",
    "    print(f'True Negatives: {confusion_matrix(y_validate, preds)[0][0]}')\n",
    "    print(f'False Negatvies: {confusion_matrix(y_validate, preds)[1][0]}')\n",
    "    print(classification_report(y_validate, preds))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4647b",
   "metadata": {},
   "source": [
    "After comparing each model's performance on the validate set to its performance on the training set, it seems that model 3 has the most consistent performance from set to set. However, model 2 actually performed the best on the validate data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766b025",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30107e1d",
   "metadata": {},
   "source": [
    "### Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9e4cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Instantiate the model\n",
    "knn_1 = KNeighborsClassifier(n_neighbors = 1, weights = 'uniform')\n",
    "\n",
    "#Fit the model to training data\n",
    "knn_1.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on training data\n",
    "knn_1_preds = knn_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7ad69",
   "metadata": {},
   "source": [
    "### Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "373119a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = knn_1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05f7bff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  297   10\n",
       "1   21  170"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, knn_1_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21f17b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       307\n",
      "           1       0.94      0.89      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.94      0.93      0.93       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, knn_1_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b6669",
   "metadata": {},
   "source": [
    "### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74749406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9377510040160643\n",
      "True Positives: 170\n",
      "True Negatives: 297\n",
      "False Positives: 10\n",
      "False Negatives: 21\n"
     ]
    }
   ],
   "source": [
    "#Precision, Recall, f1-score, and support are all clearly labeled above.\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('True Positives: 170')\n",
    "print('True Negatives: 297')\n",
    "print('False Positives: 10')\n",
    "print('False Negatives: 21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b72ed",
   "metadata": {},
   "source": [
    "### Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5f29f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "knn_2 = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform')\n",
    "\n",
    "#Fit the model\n",
    "knn_2.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "knn_2_preds = knn_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d57e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = knn_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bbd7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  267   40\n",
       "1   68  123"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, knn_2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8612447c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       307\n",
      "           1       0.75      0.64      0.69       191\n",
      "\n",
      "    accuracy                           0.78       498\n",
      "   macro avg       0.78      0.76      0.76       498\n",
      "weighted avg       0.78      0.78      0.78       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_train, knn_2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b26871ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7831325301204819\n",
      "True Positives: 123\n",
      "True Negatives: 267\n",
      "False Positives: 40\n",
      "False Negatives: 68\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print('True Positives: 123')\n",
    "print('True Negatives: 267')\n",
    "print('False Positives: 40')\n",
    "print('False Negatives: 68')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23010570",
   "metadata": {},
   "source": [
    "### Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59a9c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "knn_3 = KNeighborsClassifier(n_neighbors = 20, weights = 'uniform')\n",
    "\n",
    "#Fit the model\n",
    "knn_3.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "knn_3_preds = knn_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c3e25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "accuracy = knn_3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "787e56cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  263   44\n",
       "1   87  104"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "pd.DataFrame(confusion_matrix(y_train, knn_3_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6607728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.751429</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.727066</td>\n",
       "      <td>0.732741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.856678</td>\n",
       "      <td>0.544503</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.700590</td>\n",
       "      <td>0.736948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.800609</td>\n",
       "      <td>0.613569</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.707089</td>\n",
       "      <td>0.728873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.751429    0.702703  0.736948    0.727066      0.732741\n",
       "recall       0.856678    0.544503  0.736948    0.700590      0.736948\n",
       "f1-score     0.800609    0.613569  0.736948    0.707089      0.728873\n",
       "support    307.000000  191.000000  0.736948  498.000000    498.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification Report\n",
    "pd.DataFrame(classification_report(y_train, knn_3_preds, output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e30cb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7369477911646586\n",
      "True Positives: 104\n",
      "True Negatives: 263\n",
      "False Positives: 44\n",
      "False Negatives: 87\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print('True Positives: 104')\n",
    "print('True Negatives: 263')\n",
    "print('False Positives: 44')\n",
    "print('False Negatives: 87')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220687ce",
   "metadata": {},
   "source": [
    "### What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8f116",
   "metadata": {},
   "source": [
    "As k was increased, the overall accuracy of the model went down. The first model with k = 1 performed the best on the in-sample data. I think the reason for this is that as k increases, the likelihood that unrelated data points get taken into consideration increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80009a14",
   "metadata": {},
   "source": [
    "### Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cfd1be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Neighbors</th>\n",
       "      <th>True Positves</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>True Negatives</th>\n",
       "      <th>False Negatvies</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>107</td>\n",
       "      <td>33</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.208779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>107</td>\n",
       "      <td>36</td>\n",
       "      <td>0.714953</td>\n",
       "      <td>0.068179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>106</td>\n",
       "      <td>44</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.064051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_Neighbors  True Positves  False Positives  True Negatives  \\\n",
       "0            1             49               25             107   \n",
       "1           10             46               25             107   \n",
       "2           20             38               26             106   \n",
       "\n",
       "   False Negatvies  Accuracy  Difference  \n",
       "0               33  0.728972    0.208779  \n",
       "1               36  0.714953    0.068179  \n",
       "2               44  0.672897    0.064051  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [knn_1, knn_2, knn_3]\n",
    "metrics = []\n",
    "\n",
    "for model in models:\n",
    "    #Make predictions\n",
    "    knn_preds = model.predict(X_validate)\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    \n",
    "    output = {\n",
    "        'N_Neighbors': model.n_neighbors,\n",
    "        'True Positves': confusion_matrix(y_validate, knn_preds)[1][1],\n",
    "        'False Positives': confusion_matrix(y_validate, knn_preds)[0][1],\n",
    "        'True Negatives': confusion_matrix(y_validate, knn_preds)[0][0],\n",
    "        'False Negatvies': confusion_matrix(y_validate, knn_preds)[1][0],\n",
    "        'Accuracy': model.score(X_validate, y_validate),\n",
    "        'Difference': train_accuracy - model.score(X_validate, y_validate)\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56359d",
   "metadata": {},
   "source": [
    "The first model with k = 1 performed the best on our validate data set, but also had a huge change in accuracy from the training set. For this reason, I think model 2 with k = 10 is the best choice. It offers nearly the same accuracy as the first model on the validate set, but with a much smaller change in accuracy from the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28e809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
